\documentclass{exercise}
\usepackage{global-settings}
\usepackage{multicol}
\usepackage{subcaption}
\usepackage[version=4]{mhchem}
\def\modelsolution{1}

\setcounter{tutorial}{8}
\setcounter{exercise}{1}
\release{Mittwoch, 20.11.2024}
\submission{Mittwoch, 27.11.2024, 14 Uhr}


\DeclareMathOperator\arctanh{arctanh}

\begin{document}

\clearpage
\makeheader

\exercise{Fragen (2P)}
Stellen Sie \emph{pro Person} zwei relevante Fragen zu den Inhalten der Vorlesung \enquote{Einf\"uhrung in die Kern- und Elementarteilchenphysik}.

\exercise{Lorentztransformationen (7P)}

Die Lorentzgruppe ist die Gruppe an Transformationen auf Vierervektoren, unter denen die Minkowskimetrik (die Metrik des flachen Raumes) invariant bleibt:
\begin{equation}
    L := O(3,1) =  \left\{ \Lambda \in \mathbb{R}^{4 \times 4} \, | \, \Lambda_{\phantom{\mu} \mu}^\alpha \, g_{\alpha \beta} \, \Lambda_{\phantom{\nu} \nu}^\beta   = g_{\mu \nu} \right\} \,.
\end{equation} 

Eine wichtige Untergruppe der Lorentztransformationen (LTs) sind die eigentlich-orthochronen Lorentztransformationen
\begin{equation}
    L_+^\uparrow := \left\{ \Lambda \in L \, | \, \det \Lambda = 1 \, \wedge \, \text{sgn} \Lambda^0_{\phantom{0} 0} = 1 \right\} \,,
\end{equation} 
die ausschließlich Boosts und Rotationen umfasst.
Neben den eigentlich-orthochronen LTs existieren drei weitere Komponenten, die zusammen die Lorentzgruppe bilden.
Diese sind über Parit\"at und/oder Zeitumkehr mit der Untergruppe der eigentlich-orthochronen LTs verbunden.

\begin{enumerate}
    \item Geben Sie die Matrixformen der Paritäts- und Zeitumkehrtransformationen $P$ und $T$ an.
    
    \solution{
    \begin{align*}
        P &= \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & -1 & 0 & 0 \\
            0 & 0 & -1 & 0 \\
            0 & 0 & 0 & -1
        \end{pmatrix}
    \end{align*}
    \begin{align*}
        T &= \begin{pmatrix}
            -1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 1
        \end{pmatrix}
    \end{align*}
    \textit{1 Punkt}
    }

    \item Zeigen Sie, dass $\det \Lambda = \pm 1$ gilt. 
    \solution{
        Wir starten mit
        \begin{equation}
            \Lambda^T g \Lambda = g \,.
        \end{equation}
        Dann folgt
        \begin{align*}
            \det(\Lambda^T) \det(g) \det(\Lambda) &= \det(g) \\
            \det(\Lambda^T) \det(\Lambda) &= 1 \\
            \det(\Lambda)^2 &= 1 \\
            \det(\Lambda) &= \pm 1 \,.
        \end{align*}
        \textit{1 Punkt}
    }

    \item Betrachten Sie einen Lorentzboost in $x$-Richtung mit
    \begin{equation}
        \label{eq:BoostsMatrix}
        \Lambda = \begin{pmatrix}
            \gamma & -\beta \gamma & 0 & 0 \\
            -\beta \gamma & \gamma & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 1
        \end{pmatrix}
    \end{equation}
    und dem bekannten $\gamma = 1/\sqrt{1-\beta^2}$.
    Zeigen Sie, dass $\Lambda \in L_+^\uparrow$ gilt.

    \solution{
        Wir teilen den Beweis in drei Schritte auf:
        \begin{enumerate}
            \item  $\Lambda \in L$
            
            Offensichtlich ist $\Lambda$ eine reelle $4 \times 4$ da $\gamma \,, \beta \in \mathbb{R}$.
            Des Weiteren gilt:
            \begin{align*}
                \Lambda^T g \Lambda &= \begin{pmatrix}
                    \gamma & -\beta \gamma & 0 & 0 \\
                    -\beta \gamma & \gamma & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1
                    \end{pmatrix}^T
                    \begin{pmatrix}
                    1 & 0 & 0 & 0 \\
                    0 & -1 & 0 & 0 \\
                    0 & 0 & -1 & 0 \\
                    0 & 0 & 0 & -1
                    \end{pmatrix}
                    \begin{pmatrix}
                    \gamma & -\beta \gamma & 0 & 0 \\
                    -\beta \gamma & \gamma & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1
                    \end{pmatrix} \\
                    &= \begin{pmatrix}
                    \gamma & +\beta \gamma & 0 & 0 \\
                    -\beta \gamma & -\gamma & 0 & 0 \\
                    0 & 0 & -1 & 0 \\
                    0 & 0 & 0 & -1
                    \end{pmatrix}
                    \begin{pmatrix}
                    \gamma & -\beta \gamma & 0 & 0 \\
                    -\beta \gamma & \gamma & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1  
                    \end{pmatrix} \\
                    &= \begin{pmatrix}
                    1 & 0 & 0 & 0 \\
                    0 & -1 & 0 & 0 \\
                    0 & 0 & -1 & 0 \\
                    0 & 0 & 0 & -1
                    \end{pmatrix} = g \, 
            \end{align*}
            wobei wir $\gamma^2 = 1 - \beta^2$ nutzen.

            \item  $\text{sgn} \Lambda^0_{\phantom{0} 0} = 1$

            Das stimmt offensichtlich, weil $\Lambda^0_{\phantom{0} 0} = \gamma > 0$ immer gilt.

            \item  $\det \Lambda = 1$ 
            \begin{align*}
                \det \Lambda &= \det \begin{pmatrix}
                    \gamma & -\beta \gamma & 0 & 0 \\
                    -\beta \gamma & \gamma & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1 \\
                \end{pmatrix} \\
                &= 1 \cdot \begin{vmatrix}
                    \gamma & -\beta \gamma & 0 \\
                    -\beta \gamma & \gamma & 0 \\
                    0 & 0 & 1 \\
                    \end{vmatrix} \\
                &= \gamma^2 - \beta^2 \gamma^2 = 1 \,.
            \end{align*}
        \end{enumerate}
        \textit{2 Punkte}
    }
    \item Drücken sie \autoref{eq:BoostsMatrix} durch die Rapidität $\eta = \arctanh\left(\beta\right)$ aus. Welchen Vorteil kann es haben mit $\eta$ zu rechnen?
    \solution{Ein möglicher Weg wäre: 
        \begin{align*}
            \beta           &= \tanh(\eta)\\
            \gamma          &= \dfrac{1}{\sqrt{1 - \tanh^2(\eta)}}\\
                            &= \dfrac{1}{\sqrt{ \dfrac{\cosh^2(\eta)}{\cosh^2(\eta)} - \dfrac{\sinh^2(\eta)}{\cosh^2(\eta)}}} \, \text{mit}\, \cosh^2(\eta) - \sinh^2(\eta) = 1\\
                            &= \cosh(\eta) \\
            \Rightarrow  \beta \gamma   &= \tanh(\eta)\cosh(\eta) = \sinh(\eta)
        \end{align*}
        Zusammen gilt:
        \begin{align*}
               \Lambda &= \begin{pmatrix}
                \cosh(\eta) & -\sinh(\eta) & 0 & 0 \\
                -\sinh(\eta) & \cosh(\eta) & 0 & 0 \\
                0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 1 \\
            \end{pmatrix} \\
        \end{align*}
        Die Rapidität geht über den gesamten Wertebereich $\eta \in \left(-\infty, \infty\right)$, was in­tu­i­tiver sein kann als $v \in \left(-c, c\right)$.
        Außderdem ist $\eta$ additiv $\eta_\text{ges} = \eta_1 + \eta_2$\,.
        Es muss nicht die Formel für die relativistische Geschwindigkeitaddition verwendet werden.\\
        \textit{1 Punkt}
        }
        \item Für einen kovarianten Vektor $x^{\mu}$ gilt unter einer LT $x^{\mu} \rightarrow x'^{\mu} = \Lambda_{\phantom{\nu} \nu}^\mu x^{\nu}\,.$
        Bestimmen Sie das allgemein Transformationverhalten eines kontravarianten Vektors $x_{\mu}$.
        \solution{
           $x_{\mu} \rightarrow x'_{\mu} = g_{\mu \nu} x'^{\nu} = g_{\mu \nu} \Lambda_{\phantom{\rho} \rho}^\nu x^{\rho} = \Lambda_{\mu \rho} x^{\rho} = \Lambda_{ \mu}^{\phantom{\nu} \nu} g_{\nu \rho} x^\rho = \Lambda_{ \mu}^{\phantom{\nu} \nu} x_\nu$ \\
           \textit{0,5 Punkte}
           }
        \item Bestimmen Sie das Transformationenverhalten der kovarianten Ableitung $\partial_\mu = \dfrac{\partial}{\partial x^\mu}$.\\
        \textit{Hinweis: Nutzen Sie, dass eine LT auch als $\dfrac{\partial x^\beta}{\partial x'^\alpha} = \Lambda^{\phantom{\beta} \beta}_\alpha$ geschrieben werden kann.}
        \solution{
            \begin{align}
                \dfrac{\partial}{\partial x^\mu} \rightarrow \dfrac{\partial}{\partial x'^\mu} = \dfrac{\partial x^\nu}{\partial x'^\mu}\dfrac{1}{\partial x^\nu} = \Lambda^{\phantom{\nu} \nu}_\mu \dfrac{1}{\partial x^\nu} = \Lambda^{\phantom{\nu} \nu}_\mu \partial_\nu\\
            \end{align}
            Die kovariante Ableitung transformiert wie eine kontravarianter Vektor.
            \textit{1 Punkt}
        }
        \item Zeigen Sie, dass eine Größe $x^\mu x_\mu$ tatsächlich invariant unter einer LT $x^\mu \rightarrow x'^\mu$ ist.
        \solution{
            \begin{align}
                x^\mu x_\mu = g_{\mu \nu} x^\mu x^\nu \rightarrow g_{\mu \nu} \Lambda_{\phantom{\rho} \rho}^\mu x^{\rho}  \Lambda_{\phantom{\sigma} \sigma}^\nu x^{\sigma} = \Lambda_{\phantom{\rho} \rho}^\mu g_{\mu \nu} \Lambda_{\phantom{\sigma} \sigma}^\nu  x^{\rho} x^{\sigma} = g_{\sigma \rho} x^{\rho} x^{\sigma} = x^{\rho} x_{\rho} = x^{\mu} x_{\mu}
            \end{align}
            \textit{0,5 Punkte}
        }
\end{enumerate}
\end{document}